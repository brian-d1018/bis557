% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ols_gd_hw2b.R
\name{ols_gd_hw2b}
\alias{ols_gd_hw2b}
\title{OLS with Gradient Descent}
\usage{
ols_gd_hw2b(form, d, b_0, learn_rate, max_iter, contrasts = NULL)
}
\arguments{
\item{form}{linear model formula}

\item{d}{data frame}

\item{b_0}{parameters of model: column vector of initialized coefficients}

\item{learn_rate}{the initialized learning rate (aka step size)}

\item{max_iter}{the maximum number of iterations for this algorithm}

\item{contrasts}{optional list of constants for factor variables aka contrast}
}
\value{
the estimated coefficients, as well as the penalty (loss)
}
\description{
This function uses the gradient descent algorithm (matrix form)
to solve OLS and the penalty based on out-of-sample accuracy.
}
\examples{
set.seed(2020)
x <- -30:30
df <- data.frame(y = 6 + 7*x + rnorm(length(x)), x = x)
bis557::ols_gd_hw2b(form = y ~ ., d = df, b_0 = rep(1e-16, 2),
                    learn_rate = 0.18, max_iter = 1e5)

}
